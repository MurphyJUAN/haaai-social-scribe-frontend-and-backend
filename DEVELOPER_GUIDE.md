# HAAAI Social Scribe - é–‹ç™¼è€…å®Œæ•´æŒ‡å—

> ç¤¾å·¥è¨ªè¦–å ±å‘Šè‡ªå‹•ç”Ÿæˆç³»çµ±å®Œæ•´æŠ€è¡“æ–‡æª”

## ğŸ“‹ ç›®éŒ„

1. [å°ˆæ¡ˆæ¦‚è¿°](#1-å°ˆæ¡ˆæ¦‚è¿°)
2. [å‰ç«¯æ¶æ§‹](#2-å‰ç«¯æ¶æ§‹)
3. [å¾Œç«¯æ¶æ§‹](#3-å¾Œç«¯æ¶æ§‹)
4. [æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„](#4-æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„)
5. [é–‹ç™¼ç’°å¢ƒè¨­å®š](#5-é–‹ç™¼ç’°å¢ƒè¨­å®š)
6. [API æ•´åˆ](#6-api-æ•´åˆ)
7. [éƒ¨ç½²æŒ‡å—](#7-éƒ¨ç½²æŒ‡å—)
8. [é–‹ç™¼å·¥ä½œæµç¨‹](#8-é–‹ç™¼å·¥ä½œæµç¨‹)
9. [æ•…éšœæ’é™¤](#9-æ•…éšœæ’é™¤)

---

## 1. å°ˆæ¡ˆæ¦‚è¿°

### 1.1 å°ˆæ¡ˆç›®çš„

HAAAI Social Scribe æ˜¯ä¸€å€‹åŸºæ–¼ AI çš„ç¤¾å·¥è¨ªè¦–å ±å‘Šè‡ªå‹•ç”Ÿæˆç³»çµ±ï¼Œæ—¨åœ¨å”åŠ©ç¤¾å·¥å¸«å¿«é€Ÿå°‡è¨ªè«‡é€å­—ç¨¿è½‰æ›ç‚ºçµæ§‹åŒ–çš„å°ˆæ¥­å ±å‘Šã€‚

**æ ¸å¿ƒåƒ¹å€¼ï¼š**
- ğŸš€ **æ•ˆç‡æå‡**: å°‡è€—æ™‚æ•¸å°æ™‚çš„å ±å‘Šæ’°å¯«ç¸®çŸ­è‡³åˆ†é˜ç´šåˆ¥
- ğŸ¯ **å°ˆæ¥­æ¨™æº–**: ç¢ºä¿å ±å‘Šç¬¦åˆç¤¾å·¥å°ˆæ¥­è¦ç¯„å’Œæ ¼å¼è¦æ±‚
- ğŸ¤– **AI è¼”åŠ©**: çµåˆå¤šç¨® LLM æ¨¡å‹æä¾›æ™ºèƒ½åŒ–è™•ç†
- ğŸ“Š **è¦–è¦ºåŒ–**: è‡ªå‹•ç”Ÿæˆäººç‰©é—œä¿‚åœ–è¼”åŠ©ç†è§£

### 1.2 ä¸»è¦åŠŸèƒ½

| åŠŸèƒ½æ¨¡çµ„ | æè¿° | æŠ€è¡“å¯¦ç¾ |
|---------|------|----------|
| é€å­—ç¨¿è™•ç† | æ”¯æ´éŸ³æª”å’Œæ–‡å­—æª”ä¸Šå‚³ï¼Œæä¾›ç·¨è¼¯ç•Œé¢ | Vue 3 + TypeScript |
| AI å ±å‘Šç”Ÿæˆ | å¤šæ­¥é©Ÿ AI è™•ç†ï¼Œç”Ÿæˆçµæ§‹åŒ–å ±å‘Š | Flask + OpenAI/Claude |
| äººç‰©é—œä¿‚åœ– | è‡ªå‹•è­˜åˆ¥äººç‰©é—œä¿‚ä¸¦è¦–è¦ºåŒ–å‘ˆç¾ | vis.js + AI è§£æ |
| è™•é‡è¨ˆç•« | çµæ§‹åŒ–çš„è™•é‡è¨ˆç•«ç·¨è¼¯å™¨ | Vue çµ„ä»¶ + AI è¼”åŠ© |
| æœƒè©±ç®¡ç† | å¤šæœƒè©±ä¸¦è¡Œè™•ç†ï¼Œè‡ªå‹•ç‹€æ…‹ä¿å­˜ | Pinia + å¾Œç«¯æœƒè©±ç®¡ç† |

### 1.3 æŠ€è¡“æ¶æ§‹ç¸½è¦½

```mermaid
graph TB
    A[å‰ç«¯ Vue 3] --> B[API Gateway Flask]
    B --> C[AI æ¨¡å‹å±¤]
    B --> D[æœƒè©±ç®¡ç†]
    B --> E[æª”æ¡ˆç³»çµ±]
    
    C --> F[OpenAI]
    C --> G[Claude]
    C --> H[Ollama]
    
    A --> I[ç‹€æ…‹ç®¡ç† Pinia]
    A --> J[UI çµ„ä»¶ PrimeVue]
    A --> K[è¦–è¦ºåŒ– vis.js]
```

---

## 2. å‰ç«¯æ¶æ§‹

### 2.1 æŠ€è¡“æ£§

```json
{
  "framework": "Vue 3.4.21",
  "language": "TypeScript 5.0.2",
  "build": "Vite 6.3.5",
  "ui": "PrimeVue 3.53.1",
  "styling": "Tailwind CSS 3.4.3",
  "state": "Pinia 2.1.7",
  "router": "Vue Router 4.3.0"
}
```

### 2.2 å°ˆæ¡ˆçµæ§‹

```
frontend/src/
â”œâ”€â”€ ğŸ“ components/          # å¯é‡ç”¨çµ„ä»¶
â”‚   â”œâ”€â”€ ğŸ“ Banner/         # æª”æ¡ˆä¸Šå‚³ç›¸é—œçµ„ä»¶
â”‚   â”‚   â”œâ”€â”€ BannerUpload.vue      # ä¸»è¦ä¸Šå‚³ç•Œé¢
â”‚   â”‚   â”œâ”€â”€ SecurityGuideDialog.vue  # å®‰å…¨æŒ‡å—å°è©±æ¡†
â”‚   â”‚   â””â”€â”€ UserGuideDialog.vue     # ä½¿ç”¨æŒ‡å—å°è©±æ¡†
â”‚   â”œâ”€â”€ ğŸ“ Dashboard/      # ä¸»æ§å°çµ„ä»¶
â”‚   â”‚   â””â”€â”€ DashboardPanel.vue      # åˆ†é å¼ä¸»æ§å°
â”‚   â”œâ”€â”€ ğŸ“ PersonGraph/    # äººç‰©é—œä¿‚åœ–çµ„ä»¶
â”‚   â”‚   â”œâ”€â”€ PersonGraphChat.vue     # é—œä¿‚åœ–å°è©±ç·¨è¼¯
â”‚   â”‚   â”œâ”€â”€ PersonGraphEditor.vue   # é—œä¿‚åœ–ç·¨è¼¯å™¨
â”‚   â”‚   â”œâ”€â”€ PersonGraphViewer.vue   # é—œä¿‚åœ–æª¢è¦–å™¨
â”‚   â”‚   â””â”€â”€ ğŸ“ vis-network/        # vis.js å°è£
â”‚   â”œâ”€â”€ ğŸ“ ReportConfig/   # å ±å‘Šè¨­å®šçµ„ä»¶
â”‚   â”‚   â””â”€â”€ ReportConfigPanel.vue   # å ±å‘Šåƒæ•¸è¨­å®š
â”‚   â”œâ”€â”€ ğŸ“ ReportSession/  # å ±å‘Šé¡¯ç¤ºçµ„ä»¶
â”‚   â”‚   â””â”€â”€ ReportEditor.vue        # å ±å‘Šç·¨è¼¯å™¨
â”‚   â”œâ”€â”€ ğŸ“ TreatmentPlan/  # è™•é‡è¨ˆç•«çµ„ä»¶
â”‚   â”‚   â””â”€â”€ TreatmentPlanEditor.vue # è™•é‡è¨ˆç•«ç·¨è¼¯å™¨
â”‚   â””â”€â”€ ğŸ“ TypescriptEditor/ # é€å­—ç¨¿ç·¨è¼¯
â”‚       â””â”€â”€ TypescriptEditor.vue    # é€å­—ç¨¿ç·¨è¼¯å™¨
â”œâ”€â”€ ğŸ“ stores/             # Pinia ç‹€æ…‹ç®¡ç†
â”‚   â”œâ”€â”€ useSessionStore.ts          # ä¸»è¦æœƒè©±ç‹€æ…‹
â”‚   â”œâ”€â”€ useModularSessionStore.ts   # æ¨¡çµ„åŒ–æœƒè©±ç®¡ç†
â”‚   â””â”€â”€ ğŸ“ modules/        # åŠŸèƒ½æ¨¡çµ„ç‹€æ…‹
â”‚       â”œâ”€â”€ navigationStore.ts      # å°èˆªç‹€æ…‹
â”‚       â”œâ”€â”€ personGraphStore.ts     # äººç‰©é—œä¿‚åœ–ç‹€æ…‹
â”‚       â”œâ”€â”€ reportStore.ts          # å ±å‘Šç‹€æ…‹
â”‚       â”œâ”€â”€ transcriptStore.ts      # é€å­—ç¨¿ç‹€æ…‹
â”‚       â””â”€â”€ treatmentPlanStore.ts   # è™•é‡è¨ˆç•«ç‹€æ…‹
â”œâ”€â”€ ğŸ“ router/             # Vue Router è·¯ç”±
â”œâ”€â”€ ğŸ“ views/              # é é¢çµ„ä»¶
â”œâ”€â”€ ğŸ“ utils/              # å·¥å…·å‡½æ•¸
â””â”€â”€ ğŸ“ assets/             # éœæ…‹è³‡æº
```

### 2.3 æ ¸å¿ƒçµ„ä»¶è©³è§£

#### 2.3.1 BannerUpload çµ„ä»¶

**åŠŸèƒ½**: æª”æ¡ˆä¸Šå‚³å’Œåˆå§‹è¨­å®š

```vue
<template>
  <div class="upload-container">
    <!-- æª”æ¡ˆä¸Šå‚³å€åŸŸ -->
    <div class="upload-area" @drop="handleDrop" @dragover.prevent>
      <input type="file" @change="handleFileSelect" />
    </div>
    
    <!-- ä½¿ç”¨æŒ‡å— -->
    <UserGuideDialog v-model:visible="showGuide" />
    
    <!-- å®‰å…¨æŒ‡å— -->
    <SecurityGuideDialog v-model:visible="showSecurity" />
  </div>
</template>

<script setup lang="ts">
// æª”æ¡ˆè™•ç†é‚è¼¯
const handleFileSelect = (event: Event) => {
  const file = (event.target as HTMLInputElement).files?.[0]
  if (file) {
    sessionStore.setAudioFile(file)
  }
}
</script>
```

#### 2.3.2 DashboardPanel çµ„ä»¶

**åŠŸèƒ½**: çµ±ä¸€çš„åˆ†é å¼å·¥ä½œç•Œé¢

```vue
<template>
  <TabView>
    <TabPanel header="é€å­—ç¨¿ç·¨è¼¯">
      <TypescriptEditor />
    </TabPanel>
    
    <TabPanel header="å ±å‘Šç”Ÿæˆ">
      <ReportEditor />
    </TabPanel>
    
    <TabPanel header="äººç‰©é—œä¿‚åœ–">
      <PersonGraphEditor />
    </TabPanel>
    
    <TabPanel header="è™•é‡è¨ˆç•«">
      <TreatmentPlanEditor />
    </TabPanel>
  </TabView>
</template>
```

#### 2.3.3 PersonGraphEditor çµ„ä»¶

**åŠŸèƒ½**: äººç‰©é—œä¿‚åœ–ç·¨è¼¯å’Œè¦–è¦ºåŒ–

```vue
<template>
  <div class="flex gap-4">
    <!-- å·¦å´ï¼šé—œä¿‚åœ–é¡¯ç¤º -->
    <div class="flex-1">
      <PersonGraphViewer graph-type="person" />
    </div>
    
    <!-- å³å´ï¼šAI å°è©±ç·¨è¼¯ -->
    <div class="flex-1">
      <PersonGraphChat graph-type="person" />
    </div>
  </div>
</template>
```

### 2.4 ç‹€æ…‹ç®¡ç†æ¶æ§‹

#### 2.4.1 ä¸»è¦ Store çµæ§‹

```typescript
// useSessionStore.ts - æ ¸å¿ƒæœƒè©±ç‹€æ…‹
export const useSessionStore = defineStore('session', () => {
  // åŸºæœ¬ç‹€æ…‹
  const sessionId = ref('')
  const audioFile = ref<File | null>(null)
  const transcriptText = ref('')
  const reportText = ref('')
  
  // å ±å‘Šè¨­å®š
  const reportConfig = ref<ReportConfig>({
    template: 'é€šç”¨ç¤¾å·¥è©•ä¼°å ±å‘Š',
    selectedSections: [],
    customSettings: {}
  })
  
  // æ­¥é©Ÿç®¡ç†
  const currentStep = ref(0)
  const stepValidation = ref([false, false, false, false])
  
  // Actions
  const setTranscriptText = (text: string) => {
    transcriptText.value = text
  }
  
  const setReportText = (text: string) => {
    reportText.value = text
  }
  
  return {
    // State
    sessionId, audioFile, transcriptText, reportText,
    reportConfig, currentStep, stepValidation,
    
    // Actions
    setTranscriptText, setReportText
  }
}, {
  persist: {
    storage: localStorage,
    paths: ['sessionId', 'transcriptText', 'reportText', 'reportConfig']
  }
})
```

#### 2.4.2 æ¨¡çµ„åŒ–ç‹€æ…‹ç®¡ç†

```typescript
// personGraphStore.ts - äººç‰©é—œä¿‚åœ–ç‹€æ…‹
export const usePersonGraphStore = defineStore('personGraph', () => {
  const personGraphJson = ref('')
  const personGraphStage = ref<'idle' | 'generating' | 'done' | 'error'>('idle')
  
  const hasPersonGraph = computed(() => !!personGraphJson.value)
  const isPersonGraphGenerating = computed(() => personGraphStage.value === 'generating')
  
  function setPersonGraphJson(json: string) {
    personGraphJson.value = json
  }
  
  function setPersonGraphStage(stage: 'idle' | 'generating' | 'done' | 'error') {
    personGraphStage.value = stage
  }
  
  return {
    personGraphJson, personGraphStage,
    hasPersonGraph, isPersonGraphGenerating,
    setPersonGraphJson, setPersonGraphStage
  }
})
```

---

## 3. å¾Œç«¯æ¶æ§‹

### 3.1 æŠ€è¡“æ£§

```python
# requirements.txt
Flask==3.0.0           # Web æ¡†æ¶
openai==1.3.0          # OpenAI API
anthropic==0.52.2      # Claude API
ollama==0.1.7          # Ollama æœ¬åœ°æ¨¡å‹
flask-cors==4.0.0      # CORS æ”¯æ´
```

### 3.2 å°ˆæ¡ˆçµæ§‹

```
backend/
â”œâ”€â”€ ğŸ“„ app.py                    # Flask ä¸»æ‡‰ç”¨
â”œâ”€â”€ ğŸ“ api/                     # API è·¯ç”±æ¨¡çµ„
â”‚   â”œâ”€â”€ report_routes.py        # å ±å‘Šç”Ÿæˆ API
â”‚   â”œâ”€â”€ graph_routes.py         # äººç‰©é—œä¿‚åœ– API
â”‚   â””â”€â”€ treatment_routes.py     # è™•é‡è¨ˆç•« API
â”œâ”€â”€ ğŸ“ prompt_core/            # æ ¸å¿ƒ Prompt ç®¡ç†
â”‚   â”œâ”€â”€ chat.py                # LLM API å°è£
â”‚   â””â”€â”€ prompt.py              # Prompt æ¨¡æ¿ç®¡ç†
â”œâ”€â”€ ğŸ“ utils/                  # å·¥å…·æ¨¡çµ„
â”‚   â”œâ”€â”€ session_manager.py     # æœƒè©±ç®¡ç†
â”‚   â””â”€â”€ file_manager.py        # æª”æ¡ˆç®¡ç†
â”œâ”€â”€ ğŸ“ temp_sessions/          # æš«å­˜æœƒè©±ç›®éŒ„
â”œâ”€â”€ ğŸ“„ run.py                  # å ±å‘Šç”Ÿæˆä¸»æµç¨‹
â”œâ”€â”€ ğŸ“„ person_graph.py         # äººç‰©é—œä¿‚åœ–ç”Ÿæˆ
â”œâ”€â”€ ğŸ“„ person_graph_chat.py    # äººç‰©é—œä¿‚åœ–å°è©±
â”œâ”€â”€ ğŸ“„ *.json                  # é…ç½®æª”æ¡ˆ
â””â”€â”€ ğŸ“„ setting.json            # LLM æ¨¡å‹è¨­å®š
```

### 3.3 API è·¯ç”±è¨­è¨ˆ

#### 3.3.1 Flask æ‡‰ç”¨åˆå§‹åŒ–

```python
# app.py
from flask import Flask
from flask_cors import CORS
from api.report_routes import report_bp
from api.graph_routes import graph_bp
from api.treatment_routes import treatment_bp

app = Flask(__name__)
CORS(app)

# è¨»å†Šè—åœ–
app.register_blueprint(report_bp)
app.register_blueprint(graph_bp)
app.register_blueprint(treatment_bp)

@app.route('/api/health', methods=['GET'])
def health_check():
    return {'status': 'healthy', 'message': 'API is running'}

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5353, debug=True)
```

#### 3.3.2 å ±å‘Šç”Ÿæˆ API

```python
# api/report_routes.py
from flask import Blueprint, request, Response
import subprocess
import sys

report_bp = Blueprint('report', __name__)

@report_bp.route('/api/run', methods=['POST'])
def run_report():
    """ç¤¾å·¥å ±å‘Šç”Ÿæˆ API"""
    data = request.get_json()
    
    def generate():
        # å¯«å…¥è¼¸å…¥æª”æ¡ˆ
        input_file = session_manager.get_step_specific_file_path(
            session_id, 'report', 'input'
        )
        with open(input_file, 'w', encoding='utf-8') as f:
            f.write(data['text'])
        
        # åŸ·è¡Œå ±å‘Šç”Ÿæˆè…³æœ¬
        process = subprocess.Popen([
            sys.executable, 'run.py',
            '--session-id', session_id,
            '--input-file', input_file,
            '--config-file', config_file
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        # æµå¼è¼¸å‡º
        for line in process.stdout:
            yield line
        
        process.stdout.close()
        process.wait()
    
    return Response(generate(), mimetype='application/x-ndjson')
```

#### 3.3.3 äººç‰©é—œä¿‚åœ– API

```python
# api/graph_routes.py
@graph_bp.route('/api/PersonGraph', methods=['POST'])
def run_person_graph():
    """äººç‰©é—œä¿‚åœ–ç”Ÿæˆ API"""
    data = request.get_json()
    text = data.get('text', '')
    session_id = data.get('sessionId', str(uuid.uuid4()))
    
    def generate():
        print(f"æ”¶åˆ°äººç‰©é—œä¿‚åœ–è«‹æ±‚ï¼Œæœƒè©±ID: {session_id}")
        
        # æº–å‚™è¼¸å…¥æª”æ¡ˆ
        input_file = session_manager.get_step_specific_file_path(
            session_id, 'person_graph', 'input'
        )
        with open(input_file, 'w', encoding='utf-8') as f:
            f.write(text)
        
        # åŸ·è¡Œäººç‰©é—œä¿‚åœ–ç”Ÿæˆè…³æœ¬
        process = subprocess.Popen([
            sys.executable, 'person_graph.py',
            '--session-id', session_id,
            '--input-file', input_file,
            '--config-file', 'person_graph.json'
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        for line in process.stdout:
            yield line
        process.stdout.close()
        process.wait()
    
    return Response(generate(), mimetype='application/x-ndjson')

@graph_bp.route('/api/PersonGraphChat', methods=['POST'])
def person_graph_chat():
    """äººç‰©é—œä¿‚åœ–å°è©±ç·¨è¼¯ API"""
    data = request.get_json()
    message = data.get('message', '')
    current_graph = data.get('currentGraph', '')
    transcript = data.get('transcript', '')
    session_id = data.get('sessionId', str(uuid.uuid4()))
    
    def generate():
        # æº–å‚™å°è©±è¼¸å…¥
        input_file = session_manager.get_step_specific_file_path(
            session_id, 'person_graph_chat', 'input'
        )
        with open(input_file, 'w', encoding='utf-8') as f:
            f.write(f"åŸå§‹é€å­—ç¨¿:\n{transcript}\n\nç•¶å‰äººç‰©é—œä¿‚åœ–JSON:\n{current_graph}\n\nç”¨æˆ¶æŒ‡ä»¤:\n{message}")
        
        # åŸ·è¡Œå°è©±è™•ç†è…³æœ¬
        process = subprocess.Popen([
            sys.executable, 'person_graph_chat.py',
            '--session-id', session_id,
            '--input-file', input_file,
            '--message', message,
            '--current-graph', current_graph or '{}',
            '--transcript', transcript,
            '--graph-type', 'person',
            '--config-file', 'person_graph_chat.json'
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        for line in process.stdout:
            yield line
        process.stdout.close()
        process.wait()
    
    return Response(generate(), mimetype='application/x-ndjson')
```

### 3.4 æœƒè©±ç®¡ç†ç³»çµ±

```python
# utils/session_manager.py
import os
import shutil
from pathlib import Path

class SessionManager:
    def __init__(self, base_dir='temp_sessions'):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)
    
    def get_session_dir(self, session_id: str) -> Path:
        """ç²å–æœƒè©±ç›®éŒ„"""
        session_dir = self.base_dir / session_id
        session_dir.mkdir(exist_ok=True)
        return session_dir
    
    def get_step_specific_file_path(self, session_id: str, step: str, file_type: str) -> str:
        """ç²å–æ­¥é©Ÿå°ˆç”¨æª”æ¡ˆè·¯å¾‘"""
        session_dir = self.get_session_dir(session_id)
        timestamp = int(time.time() * 1000)
        filename = f"{step}_{file_type}_{timestamp}.txt"
        return str(session_dir / filename)
    
    def cleanup_session_files(self, session_id: str):
        """æ¸…ç†æœƒè©±æª”æ¡ˆ"""
        session_dir = self.get_session_dir(session_id)
        if session_dir.exists():
            shutil.rmtree(session_dir)
            print(f"å·²æ¸…ç†æœƒè©± {session_id} çš„æª”æ¡ˆ")

# å…¨å±€æœƒè©±ç®¡ç†å™¨å¯¦ä¾‹
session_manager = SessionManager()
```

### 3.5 AI æ¨¡å‹æ•´åˆå±¤

```python
# prompt_core/chat.py
import openai
import anthropic
import ollama
from typing import Iterator

class ChatBot:
    def __init__(self, default_model_id: str, setting_path: str = "setting.json"):
        self.default_model_id = default_model_id
        self.model_configs = self._load_settings(setting_path)
        self.api_keys = self._load_api_keys()
    
    def chat(self, messages: list, temperature: float = 0.0, 
             stream: bool = False, model_id: str = None) -> str | Iterator[str]:
        """çµ±ä¸€çš„èŠå¤©æ¥å£"""
        model_id = model_id or self.default_model_id
        config = self.model_configs.get(model_id)
        
        if not config:
            raise ValueError(f"æ¨¡å‹é…ç½®ä¸å­˜åœ¨: {model_id}")
        
        self.platform = config['platform']
        self.model = config['model']
        self.api_key = self.api_keys.get(config.get('openai_api_key') or config.get('claude_api_key'))
        
        if self.platform == 'openai':
            return self._chat_openai(messages, temperature, stream)
        elif self.platform == 'claude':
            return self._chat_claude(messages, temperature, stream)
        elif self.platform == 'ollama':
            return self._chat_ollama(messages, temperature, stream)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„å¹³å°: {self.platform}")
    
    def _chat_openai(self, messages: list, temperature: float, stream: bool):
        """OpenAI API è™•ç†"""
        client = openai.OpenAI(api_key=self.api_key)
        
        response = client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            stream=stream
        )
        
        if stream:
            for chunk in response:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
        else:
            return response.choices[0].message.content
    
    def _chat_claude(self, messages: list, temperature: float, stream: bool):
        """Claude API è™•ç†"""
        client = anthropic.Anthropic(api_key=self.api_key)
        
        if stream:
            with client.messages.stream(
                model=self.model,
                max_tokens=20000,
                messages=messages,
                temperature=temperature
            ) as stream_resp:
                for text in stream_resp.text_stream:
                    yield text
        else:
            response = client.messages.create(
                model=self.model,
                max_tokens=20000,
                messages=messages,
                temperature=temperature
            )
            return response.content[0].text
    
    def _chat_ollama(self, messages: list, temperature: float, stream: bool):
        """Ollama API è™•ç†"""
        client = ollama.Client()
        
        response = client.chat(
            model=self.model,
            messages=messages,
            stream=stream,
            options={'temperature': temperature}
        )
        
        if stream:
            for chunk in response:
                yield chunk['message']['content']
        else:
            return response['message']['content']
```

---

## 4. æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„

### 4.1 å ±å‘Šç”Ÿæˆæµç¨‹

#### 4.1.1 ä¸»è¦è™•ç†è…³æœ¬

```python
# run.py - å ±å‘Šç”Ÿæˆä¸»æµç¨‹
import argparse
import json
from prompt_core.prompt import PromptLibrary
from prompt_core.chat import PromptManager

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--session-id', required=True)
    parser.add_argument('--input-file', required=True)
    parser.add_argument('--config-file', required=True)
    
    args = parser.parse_args()
    
    # è¼‰å…¥é…ç½®
    with open(args.config_file, "r", encoding="utf-8") as f:
        run_data = json.load(f)
    
    # åˆå§‹åŒ– Prompt è™•ç†
    prompt_lib = PromptLibrary(args.config_file)
    default_model_id = run_data.get("default_model_id", "openai_gpt-4o-mini")
    pm = PromptManager(default_model_id=default_model_id)
    
    # è®€å–è¼¸å…¥æª”æ¡ˆ
    with open(args.input_file, "r", encoding="utf-8") as f:
        input_text = f.read()
    
    # è™•ç†æ¯å€‹æ­¥é©Ÿ
    steps = run_data.get("steps", [])
    conversation_id = f"session_{args.session_id}"
    
    for step in steps:
        step_name = step.get("label", "unknown")
        print(f"åŸ·è¡Œæ­¥é©Ÿ: {step_name}")
        
        # ç”Ÿæˆå•é¡Œ
        question = prompt_lib.generate(step_name, input=input_text)
        
        # åŸ·è¡Œ AI è™•ç†
        temperature = run_data.get("temperature", 0.0)
        stream = run_data.get("stream", True)
        
        if stream:
            for chunk in pm.chat(conversation_id, question, temperature=temperature, stream=True):
                print(json.dumps({"content": chunk}))
        else:
            response = pm.chat(conversation_id, question, temperature=temperature, stream=False)
            print(json.dumps({"content": response}))

if __name__ == "__main__":
    main()
```

#### 4.1.2 Prompt æ¨¡æ¿ç³»çµ±

```python
# prompt_core/prompt.py
import json
from string import Template

class PromptLibrary:
    def __init__(self, config_file_path: str):
        self.config_file_path = config_file_path
        self.templates = self._load_templates()
    
    def _load_templates(self) -> dict:
        """è¼‰å…¥ Prompt æ¨¡æ¿"""
        with open(self.config_file_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        
        templates = {}
        for step in config.get("steps", []):
            templates[step["label"]] = step["template"]
        
        return templates
    
    def generate(self, step_name: str, **kwargs) -> str:
        """ç”Ÿæˆç‰¹å®šæ­¥é©Ÿçš„ Prompt"""
        template = self.templates.get(step_name)
        if not template:
            raise ValueError(f"æ‰¾ä¸åˆ°æ­¥é©Ÿæ¨¡æ¿: {step_name}")
        
        # ä½¿ç”¨ Template é€²è¡Œè®Šæ•¸æ›¿æ›
        prompt_template = Template(template)
        return prompt_template.safe_substitute(kwargs)
```

#### 4.1.3 å ±å‘Šé…ç½®ç¯„ä¾‹

```json
// run.json - å ±å‘Šç”Ÿæˆé…ç½®
{
  "input_file": "input.txt",
  "default_model_id": "openai_gpt-4o-mini",
  "temperature": 0.3,
  "stream": true,
  "steps": [
    {
      "label": "full_report",
      "type": "chat",
      "template": "ä½ æ˜¯å°ˆæ¥­çš„ç¤¾å·¥å¸«ï¼Œè«‹æ ¹æ“šä»¥ä¸‹é€å­—ç¨¿å…§å®¹ï¼Œæ•´ç†æˆçµæ§‹åŒ–çš„ç¤¾å·¥è©•ä¼°å ±å‘Šã€‚è«‹éµå¾ªä»¥ä¸‹æ ¼å¼ï¼š\n\nä¸€ã€ä¸»è¿°è­°é¡Œ\näºŒã€å€‹æ¡ˆç‹€æ³\nä¸‰ã€å€‹æ¡ˆç‹€æ³ï¼ˆäººèº«å®‰å…¨ï¼‰\nå››ã€éœ€æ±‚è©•ä¼°èˆ‡æœå‹™å»ºè­°\n\né€å­—ç¨¿å…§å®¹ï¼š\n$input\n\nè«‹ç”Ÿæˆå®Œæ•´çš„ç¤¾å·¥è©•ä¼°å ±å‘Šï¼š"
    }
  ]
}
```

### 4.2 äººç‰©é—œä¿‚åœ–ç”Ÿæˆ

#### 4.2.1 é—œä¿‚åœ–ç”Ÿæˆè…³æœ¬

```python
# person_graph.py
import argparse
import json
from prompt_core.prompt import PromptLibrary
from prompt_core.chat import PromptManager

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--session-id', required=True)
    parser.add_argument('--input-file', required=True)
    parser.add_argument('--config-file', required=True)
    
    args = parser.parse_args()
    
    # è¼‰å…¥é…ç½®
    with open(args.config_file, "r", encoding="utf-8") as f:
        run_data = json.load(f)
    
    # åˆå§‹åŒ–è™•ç†å™¨
    prompt_lib = PromptLibrary(args.config_file)
    default_model_id = run_data.get("default_model_id", "claude_sonnet")
    pm = PromptManager(default_model_id=default_model_id)
    
    # è®€å–è¼¸å…¥
    with open(args.input_file, "r", encoding="utf-8") as f:
        input_text = f.read()
    
    # ç”Ÿæˆäººç‰©é—œä¿‚åœ–
    steps = run_data.get("steps", [])
    conversation_id = f"person_graph_{args.session_id}"
    
    for step in steps:
        if step.get("label") == "person_graph":
            question = prompt_lib.generate("person_graph", input=input_text)
            
            # æµå¼è¼¸å‡º JSON æ ¼å¼çš„é—œä¿‚åœ–
            for chunk in pm.chat(conversation_id, question, stream=True):
                print(json.dumps({"content": chunk}))

if __name__ == "__main__":
    main()
```

#### 4.2.2 é—œä¿‚åœ–é…ç½®

```json
// person_graph.json
{
  "input_file": "input.txt",
  "default_model_id": "claude_sonnet",
  "temperature": 0.0,
  "stream": true,
  "steps": [
    {
      "label": "person_graph",
      "type": "chat",
      "template": "ä½ æ˜¯å°ˆæ¥­çš„äººç‰©é—œä¿‚åˆ†æå¸«ï¼Œè«‹æ ¹æ“šé€å­—ç¨¿å…§å®¹ï¼Œç”Ÿæˆ vis.js æ ¼å¼çš„äººç‰©é—œä¿‚åœ–ã€‚\n\næ ¼å¼è¦æ±‚ï¼š\n```json\n{\n  \"nodes\": [\n    {\"id\": \"node1\", \"label\": \"äººç‰©åç¨±\", \"group\": \"family\"}\n  ],\n  \"edges\": [\n    {\"from\": \"node1\", \"to\": \"node2\", \"label\": \"é—œä¿‚\"}\n  ]\n}\n```\n\né€å­—ç¨¿å…§å®¹ï¼š\n$input\n\nè«‹ç”Ÿæˆ JSON æ ¼å¼çš„äººç‰©é—œä¿‚åœ–ï¼š"
    }
  ]
}
```

#### 4.2.3 é—œä¿‚åœ–å°è©±ç·¨è¼¯

```python
# person_graph_chat.py
import argparse
import json
from prompt_core.prompt import PromptLibrary
from prompt_core.chat import PromptManager

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--session-id', required=True)
    parser.add_argument('--input-file', required=True)
    parser.add_argument('--message', required=True)
    parser.add_argument('--current-graph', required=True)
    parser.add_argument('--transcript', required=True)
    parser.add_argument('--graph-type', default='person')
    parser.add_argument('--config-file', required=True)
    
    args = parser.parse_args()
    
    # è¼‰å…¥é…ç½®å’Œåˆå§‹åŒ–
    with open(args.config_file, "r", encoding="utf-8") as f:
        run_data = json.load(f)
    
    prompt_lib = PromptLibrary(args.config_file)
    default_model_id = run_data.get("default_model_id", "openai_gpt-4o-mini")
    pm = PromptManager(default_model_id=default_model_id)
    
    # è®€å–å®Œæ•´è¼¸å…¥
    with open(args.input_file, "r", encoding="utf-8") as f:
        full_input = f.read()
    
    # ç”Ÿæˆå°è©±å•é¡Œ
    question = prompt_lib.generate("person_graph_chat", input=full_input)
    
    # åŸ·è¡Œå°è©±è™•ç†
    conversation_id = f"person_graph_chat_{args.session_id}"
    
    # å…ˆè¼¸å‡ºå›æ‡‰
    for chunk in pm.chat(conversation_id, question, stream=True):
        if chunk.strip():
            print(json.dumps({"type": "response", "content": chunk}))
    
    # ç„¶å¾Œè¼¸å‡ºæ›´æ–°çš„ JSON
    graph_question = f"è«‹æ ¹æ“šä¸Šè¿°å°è©±ï¼Œè¼¸å‡ºæ›´æ–°å¾Œçš„å®Œæ•´ JSON æ ¼å¼äººç‰©é—œä¿‚åœ–ï¼š"
    
    for chunk in pm.chat(conversation_id, graph_question, stream=True):
        if chunk.strip():
            print(json.dumps({"type": "graph", "content": chunk}))

if __name__ == "__main__":
    main()
```

### 4.3 å‰ç«¯è¦–è¦ºåŒ–æ•´åˆ

#### 4.3.1 vis.js é—œä¿‚åœ–çµ„ä»¶

```vue
<!-- components/PersonGraph/vis-network/VisNetworkGraph.vue -->
<template>
  <div ref="networkContainer" class="w-full h-full min-h-[400px]"></div>
</template>

<script setup lang="ts">
import { ref, onMounted, watch, nextTick } from 'vue'
import { Network } from 'vis-network/standalone/umd/vis-network.min.js'

interface Props {
  graphJson: string
}

const props = defineProps<Props>()
const networkContainer = ref<HTMLElement>()
let network: Network | null = null

const initNetwork = async () => {
  if (!networkContainer.value || !props.graphJson) return
  
  try {
    const graphData = JSON.parse(props.graphJson)
    
    // è¨­å®šç¶²è·¯é¸é …
    const options = {
      nodes: {
        shape: 'dot',
        size: 20,
        font: {
          size: 14,
          color: '#333333'
        }
      },
      edges: {
        font: {
          size: 12,
          color: '#666666'
        },
        arrows: {
          to: { enabled: true, scaleFactor: 1 }
        }
      },
      physics: {
        enabled: true,
        stabilization: { iterations: 100 }
      }
    }
    
    // æ¸…ç†èˆŠç¶²è·¯
    if (network) {
      network.destroy()
    }
    
    // å»ºç«‹æ–°ç¶²è·¯
    network = new Network(networkContainer.value, graphData, options)
    
    // äº‹ä»¶ç›£è½
    network.on('click', (params) => {
      console.log('ç¯€é»é»æ“Š:', params)
    })
    
  } catch (error) {
    console.error('é—œä¿‚åœ–åˆå§‹åŒ–å¤±æ•—:', error)
  }
}

// ç›£è½æ•¸æ“šè®ŠåŒ–
watch(() => props.graphJson, () => {
  nextTick(() => {
    initNetwork()
  })
}, { immediate: true })

onMounted(() => {
  initNetwork()
})
</script>
```

#### 4.3.2 é—œä¿‚åœ–å°è©±çµ„ä»¶

```vue
<!-- components/PersonGraph/PersonGraphChat.vue -->
<template>
  <div class="h-full flex flex-col p-4">
    <h2 class="text-lg font-bold mb-4">é€šç”¨é—œä¿‚åœ–æ™ºèƒ½ç·¨è¼¯</h2>
    
    <!-- ä¸Šä¸‹æ–‡ä¿¡æ¯ -->
    <div class="mb-4 p-3 bg-blue-50 border border-blue-200 rounded-lg">
      <h3 class="text-sm font-semibold text-blue-800 mb-2">AI å¯ç”¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š</h3>
      <div class="flex flex-wrap gap-4 text-sm text-blue-700">
        <div class="flex items-center">
          <span class="w-2 h-2 rounded-full mr-2" 
                :class="sessionStore.transcriptText ? 'bg-green-500' : 'bg-gray-400'"></span>
          é€å­—ç¨¿ ({{ sessionStore.transcriptText ? `${sessionStore.transcriptText.length} å­—ç¬¦` : 'ç„¡' }})
        </div>
        <div class="flex items-center">
          <span class="w-2 h-2 rounded-full mr-2" 
                :class="currentGraphJson ? 'bg-green-500' : 'bg-gray-400'"></span>
          é€šç”¨é—œä¿‚åœ– ({{ currentGraphJson ? 'å·²è¼‰å…¥' : 'ç„¡' }})
        </div>
      </div>
    </div>
    
    <!-- å°è©±æ­·å² -->
    <div class="border rounded-lg p-4 mb-4 flex-1 overflow-y-auto bg-gray-50">
      <div v-if="chatHistory.length === 0" class="text-gray-500 text-center py-8">
        é–‹å§‹å°è©±ä¾†ç·¨è¼¯æ‚¨çš„é€šç”¨é—œä¿‚åœ–...
      </div>
      
      <div v-for="(message, index) in chatHistory" :key="index" class="mb-4">
        <div v-if="message.role === 'user'" class="flex justify-end">
          <div class="bg-blue-500 text-white rounded-lg px-4 py-2 max-w-xs">
            {{ message.content }}
          </div>
        </div>
        
        <div v-else class="flex justify-start">
          <div class="bg-white border rounded-lg px-4 py-2 max-w-xs">
            {{ message.content }}
          </div>
        </div>
      </div>
      
      <!-- è¼‰å…¥æŒ‡ç¤ºå™¨ -->
      <div v-if="isLoading" class="flex justify-start">
        <div class="bg-white border rounded-lg px-4 py-2">
          <div class="flex items-center space-x-2">
            <div class="animate-spin rounded-full h-4 w-4 border-b-2 border-blue-500"></div>
            <span>AI æ­£åœ¨æ€è€ƒ...</span>
          </div>
        </div>
      </div>
    </div>
    
    <!-- è¼¸å…¥å€åŸŸ -->
    <div class="flex space-x-2 mb-4">
      <input
        v-model="userInput"
        @keyup.enter="sendMessage"
        :disabled="isLoading"
        class="flex-1 border rounded-lg px-4 py-2 focus:outline-none focus:ring-2 focus:ring-blue-500"
        placeholder="ä¾‹å¦‚ï¼šè«‹ç§»é™¤å¼µä¸‰é€™å€‹è§’è‰²ï¼Œæˆ–è€…ï¼šè«‹åŠ å¼·æå››å’Œç‹äº”çš„é—œä¿‚..."
      />
      <button
        @click="sendMessage"
        :disabled="isLoading || !userInput.trim()"
        class="bg-blue-500 text-white px-6 py-2 rounded-lg hover:bg-blue-600 disabled:opacity-50"
      >
        ç™¼é€
      </button>
    </div>
    
    <!-- å¿«é€ŸæŒ‡ä»¤ -->
    <div class="mt-auto">
      <p class="text-sm text-gray-600 mb-2">å¿«é€ŸæŒ‡ä»¤ï¼š</p>
      <div class="flex flex-wrap gap-2">
        <button
          v-for="quickCommand in quickCommands"
          :key="quickCommand"
          @click="userInput = quickCommand"
          class="text-sm bg-gray-200 hover:bg-gray-300 px-3 py-1 rounded-full"
        >
          {{ quickCommand }}
        </button>
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, computed } from 'vue'
import { useSessionStore } from '@/stores/useSessionStore'
import { usePersonGraphStore } from '@/stores/modules/personGraphStore'

const sessionStore = useSessionStore()
const personGraphStore = usePersonGraphStore()
const userInput = ref('')
const isLoading = ref(false)
const chatHistory = ref<ChatMessage[]>([])

const quickCommands = computed(() => [
  'è«‹åŸºæ–¼é€å­—ç¨¿é‡æ–°ç”Ÿæˆé€šç”¨é—œä¿‚åœ–',
  'è«‹ç°¡åŒ–äººç‰©é—œä¿‚ï¼Œåªä¿ç•™ä¸»è¦è§’è‰²',
  'è«‹åŠ å¼·ä¸»è¦è§’è‰²ä¹‹é–“çš„é€£çµ',
  'è«‹çªå‡ºé€å­—ç¨¿ä¸­çš„è¡çªé—œä¿‚',
  'è«‹æ·»åŠ é€å­—ç¨¿ä¸­æåˆ°ä½†éºæ¼çš„äººç‰©',
  'è«‹é‡æ–°çµ„ç¹”é—œä¿‚çµæ§‹ä½¿å…¶æ›´æ¸…æ™°'
])

const currentGraphJson = computed(() => personGraphStore.personGraphJson)

async function sendMessage() {
  if (!userInput.value.trim() || isLoading.value) return
  
  const message = userInput.value.trim()
  
  // æ·»åŠ ç”¨æˆ¶æ¶ˆæ¯
  chatHistory.value.push({
    role: 'user',
    content: message,
    timestamp: new Date()
  })
  
  userInput.value = ''
  isLoading.value = true
  
  try {
    const response = await fetch('/api/PersonGraphChat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        message: message,
        currentGraph: currentGraphJson.value,
        transcript: sessionStore.transcriptText,
        sessionId: sessionStore.sessionId,
        graphType: 'person'
      })
    })
    
    // è™•ç†æµå¼å›æ‡‰
    const reader = response.body!.getReader()
    const decoder = new TextDecoder('utf-8')
    let buffer = ''
    let aiResponse = ''
    let newGraphJson = ''
    
    while (true) {
      const { value, done } = await reader.read()
      if (done) break
      
      buffer += decoder.decode(value, { stream: true })
      let lines = buffer.split('\n')
      buffer = lines.pop() || ''
      
      for (const line of lines) {
        if (!line.trim()) continue
        try {
          const obj = JSON.parse(line)
          if (obj.type === 'response') {
            aiResponse += obj.content
          } else if (obj.type === 'graph') {
            newGraphJson = obj.content
          }
        } catch (e) {
          // å¿½ç•¥è§£æéŒ¯èª¤
        }
      }
    }
    
    // æ·»åŠ  AI å›æ‡‰
    if (aiResponse) {
      chatHistory.value.push({
        role: 'assistant',
        content: aiResponse,
        timestamp: new Date()
      })
    }
    
    // æ›´æ–°é—œä¿‚åœ–
    if (newGraphJson) {
      try {
        JSON.parse(newGraphJson) // é©—è­‰æ ¼å¼
        personGraphStore.setPersonGraphJson(newGraphJson)
      } catch (e) {
        console.error('JSON æ ¼å¼éŒ¯èª¤:', newGraphJson)
      }
    }
    
  } catch (error) {
    console.error('ç™¼é€æ¶ˆæ¯å¤±æ•—:', error)
    chatHistory.value.push({
      role: 'assistant',
      content: 'æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚',
      timestamp: new Date()
    })
  } finally {
    isLoading.value = false
  }
}
</script>
```

---

## 5. é–‹ç™¼ç’°å¢ƒè¨­å®š

### 5.1 ç³»çµ±éœ€æ±‚

**åŸºæœ¬ç’°å¢ƒï¼š**
- Node.js 18+ (æ¨è–¦ 18.17.0)
- Python 3.8+ (æ¨è–¦ 3.9.0)
- Git 2.30+
- Docker 20+ (å¯é¸ï¼Œç”¨æ–¼å®¹å™¨åŒ–éƒ¨ç½²)

**IDE æ¨è–¦ï¼š**
- VS Code + Vue Language Features (Volar)
- PyCharm Professional (Python é–‹ç™¼)

### 5.2 å‰ç«¯ç’°å¢ƒè¨­å®š

#### 5.2.1 å®‰è£ç›¸ä¾å¥—ä»¶

```bash
# åˆ‡æ›åˆ°å‰ç«¯ç›®éŒ„
cd frontend

# å®‰è£ç›¸ä¾å¥—ä»¶
npm install

# å•Ÿå‹•é–‹ç™¼ä¼ºæœå™¨
npm run dev

# å»ºç½®ç”Ÿç”¢ç‰ˆæœ¬
npm run build

# é è¦½ç”Ÿç”¢ç‰ˆæœ¬
npm run preview
```

#### 5.2.2 é–‹ç™¼ä¼ºæœå™¨è¨­å®š

```typescript
// vite.config.ts
import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'
import { resolve } from 'path'

export default defineConfig({
  plugins: [vue()],
  resolve: {
    alias: {
      '@': resolve(__dirname, 'src')
    }
  },
  server: {
    port: 3000,
    host: true,
    proxy: {
      '/api': {
        target: 'http://localhost:5353',
        changeOrigin: true
      }
    }
  },
  build: {
    outDir: 'dist',
    sourcemap: true
  }
})
```

#### 5.2.3 TypeScript è¨­å®š

```json
// tsconfig.json
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "preserve",
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["src/*"]
    }
  },
  "include": ["src/**/*.ts", "src/**/*.d.ts", "src/**/*.tsx", "src/**/*.vue"],
  "references": [{ "path": "./tsconfig.node.json" }]
}
```

### 5.3 å¾Œç«¯ç’°å¢ƒè¨­å®š

#### 5.3.1 Python è™›æ“¬ç’°å¢ƒ

```bash
# å»ºç«‹è™›æ“¬ç’°å¢ƒ
python -m venv venv

# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ (Linux/Mac)
source venv/bin/activate

# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ (Windows)
venv\Scripts\activate

# å®‰è£ç›¸ä¾å¥—ä»¶
pip install -r requirements.txt

# å•Ÿå‹•é–‹ç™¼ä¼ºæœå™¨
python app.py
```

#### 5.3.2 ç’°å¢ƒè®Šæ•¸è¨­å®š

```bash
# .env (é–‹ç™¼ç’°å¢ƒ)
FLASK_ENV=development
FLASK_DEBUG=True
OPENAI_API_KEY=your_openai_api_key
CLAUDE_API_KEY=your_claude_api_key
```

#### 5.3.3 API é‡‘é‘°è¨­å®š

```json
// api_key.json
{
  "my_openai_key": "sk-your-actual-openai-api-key",
  "my_claude_key": "sk-ant-your-claude-api-key"
}
```

```json
// setting.json
[
  {
    "id": "openai_gpt-4o",
    "platform": "openai",
    "model": "gpt-4o",
    "openai_api_key": "my_openai_key"
  },
  {
    "id": "claude_sonnet",
    "platform": "claude",
    "model": "claude-3-5-sonnet-20241022",
    "claude_api_key": "my_claude_key"
  },
  {
    "id": "ollama_llama3",
    "platform": "ollama",
    "model": "llama3",
    "base_url": "http://localhost:11434"
  }
]
```

---

## 6. API æ•´åˆ

### 6.1 å‰ç«¯ API å®¢æˆ¶ç«¯

```typescript
// src/api/axiosClient.ts
import axios from 'axios'

const apiClient = axios.create({
  baseURL: '/api',
  timeout: 300000, // 5 åˆ†é˜è¶…æ™‚
  headers: {
    'Content-Type': 'application/json'
  }
})

// è«‹æ±‚æ””æˆªå™¨
apiClient.interceptors.request.use(
  (config) => {
    console.log('API è«‹æ±‚:', config.method?.toUpperCase(), config.url)
    return config
  },
  (error) => {
    console.error('API è«‹æ±‚éŒ¯èª¤:', error)
    return Promise.reject(error)
  }
)

// å›æ‡‰æ””æˆªå™¨
apiClient.interceptors.response.use(
  (response) => {
    console.log('API å›æ‡‰:', response.status, response.config.url)
    return response
  },
  (error) => {
    console.error('API å›æ‡‰éŒ¯èª¤:', error.response?.status, error.config?.url)
    return Promise.reject(error)
  }
)

export default apiClient
```

### 6.2 æµå¼ API è™•ç†

```typescript
// æµå¼ API èª¿ç”¨ç¯„ä¾‹
async function callStreamingAPI(endpoint: string, data: any) {
  const response = await fetch(endpoint, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(data)
  })
  
  if (!response.body) {
    throw new Error('No response body')
  }
  
  const reader = response.body.getReader()
  const decoder = new TextDecoder('utf-8')
  let buffer = ''
  
  try {
    while (true) {
      const { value, done } = await reader.read()
      if (done) break
      
      buffer += decoder.decode(value, { stream: true })
      let lines = buffer.split('\n')
      buffer = lines.pop() || ''
      
      for (const line of lines) {
        if (!line.trim()) continue
        
        try {
          const data = JSON.parse(line)
          // è™•ç†æ¯ä¸€è¡Œæ•¸æ“š
          yield data
        } catch (e) {
          console.warn('JSON è§£æå¤±æ•—:', line)
        }
      }
    }
  } finally {
    reader.releaseLock()
  }
}
```

### 6.3 API ç«¯é»æ–‡æª”

#### 6.3.1 å ±å‘Šç”Ÿæˆ API

**ç«¯é»:** `POST /api/run`

**è«‹æ±‚æ ¼å¼:**
```json
{
  "text": "é€å­—ç¨¿å…§å®¹",
  "template": "é€šç”¨ç¤¾å·¥è©•ä¼°å ±å‘Š",
  "selectedSections": ["ä¸€ã€ä¸»è¿°è­°é¡Œ", "äºŒã€å€‹æ¡ˆç‹€æ³"],
  "customSettings": {},
  "sessionId": "session-uuid"
}
```

**å›æ‡‰æ ¼å¼:** NDJSON æµå¼å›æ‡‰
```json
{"content": "å ±å‘Šç”Ÿæˆä¸­..."}
{"content": "ä¸€ã€ä¸»è¿°è­°é¡Œ\n"}
{"content": "æ ¹æ“šé€å­—ç¨¿åˆ†æ..."}
```

#### 6.3.2 äººç‰©é—œä¿‚åœ– API

**ç«¯é»:** `POST /api/PersonGraph`

**è«‹æ±‚æ ¼å¼:**
```json
{
  "text": "é€å­—ç¨¿å…§å®¹",
  "sessionId": "session-uuid"
}
```

**å›æ‡‰æ ¼å¼:** NDJSON æµå¼å›æ‡‰
```json
{"content": "{\"nodes\": ["}
{"content": "{\"id\": \"person1\", \"label\": \"æ¡ˆä¸»\"}"}
```

#### 6.3.3 é—œä¿‚åœ–å°è©± API

**ç«¯é»:** `POST /api/PersonGraphChat`

**è«‹æ±‚æ ¼å¼:**
```json
{
  "message": "è«‹ç§»é™¤å¼µä¸‰é€™å€‹è§’è‰²",
  "currentGraph": "{\"nodes\":[...], \"edges\":[...]}",
  "transcript": "åŸå§‹é€å­—ç¨¿",
  "sessionId": "session-uuid"
}
```

**å›æ‡‰æ ¼å¼:** NDJSON æµå¼å›æ‡‰
```json
{"type": "response", "content": "å¥½çš„ï¼Œæˆ‘å°‡ç§»é™¤å¼µä¸‰..."}
{"type": "graph", "content": "{\"nodes\":[...]}"}
```

---

## 7. éƒ¨ç½²æŒ‡å—

### 7.1 Docker å®¹å™¨åŒ–éƒ¨ç½²

#### 7.1.1 å‰ç«¯ Dockerfile

```dockerfile
# frontend/Dockerfile
FROM node:18-alpine as build

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=build /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf

EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

#### 7.1.2 å¾Œç«¯ Dockerfile

```dockerfile
# backend/Dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£ Python ä¾è³´
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ç¢¼
COPY . .

# å»ºç«‹å¿…è¦ç›®éŒ„
RUN mkdir -p temp_sessions

EXPOSE 5353

CMD ["python", "app.py"]
```

#### 7.1.3 Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  frontend:
    build: ./frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    environment:
      - API_BASE_URL=http://backend:5353

  backend:
    build: ./backend
    ports:
      - "5353:5353"
    volumes:
      - ./backend/temp_sessions:/app/temp_sessions
      - ./backend/api_key.json:/app/api_key.json
      - ./backend/setting.json:/app/setting.json
    environment:
      - FLASK_ENV=production
      - PYTHONPATH=/app

volumes:
  temp_sessions:
```

### 7.2 ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²

#### 7.2.1 Nginx é…ç½®

```nginx
# nginx.conf
server {
    listen 80;
    server_name your-domain.com;

    # å‰ç«¯éœæ…‹æª”æ¡ˆ
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
        try_files $uri $uri/ /index.html;
    }

    # API ä»£ç†
    location /api/ {
        proxy_pass http://backend:5353;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # æ”¯æ´æµå¼å›æ‡‰
        proxy_buffering off;
        proxy_cache off;
        proxy_read_timeout 300s;
    }
}
```

#### 7.2.2 ç’°å¢ƒè®Šæ•¸ç®¡ç†

```bash
# production.env
FLASK_ENV=production
FLASK_DEBUG=False
GUNICORN_WORKERS=4
GUNICORN_TIMEOUT=300
API_RATE_LIMIT=100
```

#### 7.2.3 å¥åº·æª¢æŸ¥

```python
# health_check.py
import requests
import sys

def check_health():
    try:
        response = requests.get('http://localhost:5353/api/health', timeout=10)
        if response.status_code == 200:
            print("âœ… å¥åº·æª¢æŸ¥é€šé")
            return True
        else:
            print(f"âŒ å¥åº·æª¢æŸ¥å¤±æ•—: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ å¥åº·æª¢æŸ¥ç•°å¸¸: {e}")
        return False

if __name__ == "__main__":
    if not check_health():
        sys.exit(1)
```

---

## 8. é–‹ç™¼å·¥ä½œæµç¨‹

### 8.1 Git å·¥ä½œæµç¨‹

```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone <repository-url>
cd haaai-social-scribe

# 2. å»ºç«‹åŠŸèƒ½åˆ†æ”¯
git checkout -b feature/new-feature

# 3. é–‹ç™¼éç¨‹ä¸­å®šæœŸæäº¤
git add .
git commit -m "feat: æ–°å¢åŠŸèƒ½æè¿°"

# 4. æ¨é€åˆ†æ”¯
git push origin feature/new-feature

# 5. å»ºç«‹ Pull Request
# åœ¨ GitHub/GitLab ä¸Šå»ºç«‹ PR

# 6. åˆä½µå¾Œæ¸…ç†
git checkout main
git pull origin main
git branch -d feature/new-feature
```

### 8.2 ä»£ç¢¼é¢¨æ ¼æŒ‡å—

#### 8.2.1 å‰ç«¯ä»£ç¢¼é¢¨æ ¼

```typescript
// ä½¿ç”¨ TypeScript åš´æ ¼æ¨¡å¼
interface UserData {
  id: string
  name: string
  email?: string
}

// ä½¿ç”¨ Composition API
const useUserData = () => {
  const userData = ref<UserData | null>(null)
  
  const fetchUserData = async (id: string) => {
    try {
      const response = await apiClient.get(`/users/${id}`)
      userData.value = response.data
    } catch (error) {
      console.error('ç²å–ç”¨æˆ¶æ•¸æ“šå¤±æ•—:', error)
    }
  }
  
  return {
    userData: readonly(userData),
    fetchUserData
  }
}
```

#### 8.2.2 å¾Œç«¯ä»£ç¢¼é¢¨æ ¼

```python
# ä½¿ç”¨é¡å‹æç¤º
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class SessionData:
    session_id: str
    transcript: str
    report: Optional[str] = None

def process_session_data(data: SessionData) -> Dict[str, str]:
    """è™•ç†æœƒè©±æ•¸æ“šä¸¦è¿”å›çµæœ"""
    try:
        # è™•ç†é‚è¼¯
        result = {"status": "success", "message": "è™•ç†å®Œæˆ"}
        return result
    except Exception as e:
        logger.error(f"è™•ç†æœƒè©±æ•¸æ“šå¤±æ•—: {e}")
        return {"status": "error", "message": str(e)}
```

### 8.3 æ¸¬è©¦ç­–ç•¥

#### 8.3.1 å‰ç«¯æ¸¬è©¦

```typescript
// vitest.config.ts
import { defineConfig } from 'vitest/config'
import vue from '@vitejs/plugin-vue'

export default defineConfig({
  plugins: [vue()],
  test: {
    environment: 'jsdom',
    globals: true
  }
})
```

```typescript
// tests/components/BannerUpload.test.ts
import { describe, it, expect } from 'vitest'
import { mount } from '@vue/test-utils'
import BannerUpload from '@/components/Banner/BannerUpload.vue'

describe('BannerUpload', () => {
  it('æ‡‰è©²æ­£ç¢ºæ¸²æŸ“ä¸Šå‚³ç•Œé¢', () => {
    const wrapper = mount(BannerUpload)
    expect(wrapper.find('.upload-container').exists()).toBe(true)
  })
  
  it('æ‡‰è©²è™•ç†æª”æ¡ˆä¸Šå‚³', async () => {
    const wrapper = mount(BannerUpload)
    const file = new File(['test content'], 'test.txt', { type: 'text/plain' })
    
    const input = wrapper.find('input[type="file"]')
    await input.setValue(file)
    
    // é©—è­‰æª”æ¡ˆè™•ç†é‚è¼¯
  })
})
```

#### 8.3.2 å¾Œç«¯æ¸¬è©¦

```python
# tests/test_api.py
import pytest
from app import app

@pytest.fixture
def client():
    app.config['TESTING'] = True
    with app.test_client() as client:
        yield client

def test_health_check(client):
    """æ¸¬è©¦å¥åº·æª¢æŸ¥ç«¯é»"""
    response = client.get('/api/health')
    assert response.status_code == 200
    assert response.json['status'] == 'healthy'

def test_report_generation(client):
    """æ¸¬è©¦å ±å‘Šç”Ÿæˆç«¯é»"""
    data = {
        'text': 'æ¸¬è©¦é€å­—ç¨¿å…§å®¹',
        'template': 'é€šç”¨ç¤¾å·¥è©•ä¼°å ±å‘Š',
        'sessionId': 'test-session'
    }
    
    response = client.post('/api/run', json=data)
    assert response.status_code == 200
    assert response.mimetype == 'application/x-ndjson'
```

---

## 9. æ•…éšœæ’é™¤

### 9.1 å¸¸è¦‹å•é¡Œ

#### 9.1.1 å‰ç«¯å•é¡Œ

**å•é¡Œ: Vite é–‹ç™¼ä¼ºæœå™¨ç„¡æ³•å•Ÿå‹•**
```bash
# è§£æ±ºæ–¹æ¡ˆ
rm -rf node_modules
rm package-lock.json
npm install
npm run dev
```

**å•é¡Œ: TypeScript ç·¨è­¯éŒ¯èª¤**
```bash
# æª¢æŸ¥ TypeScript é…ç½®
npx tsc --noEmit
npm run type-check
```

**å•é¡Œ: PrimeVue çµ„ä»¶æ¨£å¼ç•°å¸¸**
```typescript
// ç¢ºä¿æ­£ç¢ºå°å…¥æ¨£å¼
import 'primevue/resources/themes/lara-light-blue/theme.css'
import 'primevue/resources/primevue.min.css'
import 'primeicons/primeicons.css'
```

#### 9.1.2 å¾Œç«¯å•é¡Œ

**å•é¡Œ: Flask æ‡‰ç”¨ç„¡æ³•å•Ÿå‹•**
```bash
# æª¢æŸ¥ Python ç’°å¢ƒ
python --version
pip list

# é‡æ–°å®‰è£ä¾è³´
pip install -r requirements.txt

# æª¢æŸ¥ç«¯å£å ç”¨
lsof -i :5353
```

**å•é¡Œ: AI API èª¿ç”¨å¤±æ•—**
```python
# æª¢æŸ¥ API é‡‘é‘°è¨­å®š
import json
with open('api_key.json') as f:
    keys = json.load(f)
    print("API é‡‘é‘°å·²è¼‰å…¥:", list(keys.keys()))

# æª¢æŸ¥ç¶²è·¯é€£ç·š
import requests
response = requests.get('https://api.openai.com/v1/models', 
                       headers={'Authorization': f'Bearer {api_key}'})
print(response.status_code)
```

**å•é¡Œ: æœƒè©±æª”æ¡ˆæ¸…ç†ç•°å¸¸**
```bash
# æ‰‹å‹•æ¸…ç†æš«å­˜æª”æ¡ˆ
rm -rf temp_sessions/*

# æª¢æŸ¥ç£ç¢Ÿç©ºé–“
df -h
```

### 9.2 æ•ˆèƒ½å„ªåŒ–

#### 9.2.1 å‰ç«¯å„ªåŒ–

```typescript
// çµ„ä»¶æ‡¶åŠ è¼‰
const PersonGraphEditor = defineAsyncComponent(() => 
  import('@/components/PersonGraph/PersonGraphEditor.vue')
)

// Pinia ç‹€æ…‹æŒä¹…åŒ–å„ªåŒ–
const useSessionStore = defineStore('session', () => {
  // ... ç‹€æ…‹å®šç¾©
}, {
  persist: {
    storage: localStorage,
    paths: ['transcriptText', 'reportText'], // åªæŒä¹…åŒ–å¿…è¦ç‹€æ…‹
    serializer: {
      serialize: JSON.stringify,
      deserialize: JSON.parse
    }
  }
})
```

#### 9.2.2 å¾Œç«¯å„ªåŒ–

```python
# ä½¿ç”¨ Gunicorn ç”Ÿç”¢éƒ¨ç½²
# gunicorn_config.py
bind = "0.0.0.0:5353"
workers = 4
worker_class = "sync"
timeout = 300
keepalive = 5
max_requests = 1000
max_requests_jitter = 50
```

```python
# æœƒè©±æª”æ¡ˆè‡ªå‹•æ¸…ç†
import schedule
import time
from utils.session_manager import session_manager

def cleanup_old_sessions():
    """æ¸…ç†è¶…é 24 å°æ™‚çš„èˆŠæœƒè©±"""
    session_manager.cleanup_old_sessions(max_age_hours=24)

schedule.every(6).hours.do(cleanup_old_sessions)

# åœ¨èƒŒæ™¯åŸ·è¡Œæ¸…ç†ä»»å‹™
def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(3600)  # æ¯å°æ™‚æª¢æŸ¥ä¸€æ¬¡
```

### 9.3 å®‰å…¨æ€§è€ƒæ…®

#### 9.3.1 API å®‰å…¨

```python
# è«‹æ±‚é™åˆ¶
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

limiter = Limiter(
    app,
    key_func=get_remote_address,
    default_limits=["100 per hour"]
)

@app.route('/api/run', methods=['POST'])
@limiter.limit("10 per minute")
def run_report():
    # API é‚è¼¯
    pass
```

#### 9.3.2 æª”æ¡ˆä¸Šå‚³å®‰å…¨

```typescript
// å‰ç«¯æª”æ¡ˆé©—è­‰
const validateFile = (file: File): boolean => {
  const allowedTypes = ['audio/mp3', 'audio/wav', 'text/plain']
  const maxSize = 100 * 1024 * 1024 // 100MB
  
  if (!allowedTypes.includes(file.type)) {
    throw new Error('ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹')
  }
  
  if (file.size > maxSize) {
    throw new Error('æª”æ¡ˆå¤§å°è¶…éé™åˆ¶')
  }
  
  return true
}
```

```python
# å¾Œç«¯æª”æ¡ˆè™•ç†å®‰å…¨
import os
from werkzeug.utils import secure_filename

def save_upload_file(file):
    """å®‰å…¨åœ°ä¿å­˜ä¸Šå‚³æª”æ¡ˆ"""
    filename = secure_filename(file.filename)
    
    # æª¢æŸ¥æª”æ¡ˆé¡å‹
    allowed_extensions = {'.txt', '.mp3', '.wav', '.m4a'}
    file_ext = os.path.splitext(filename)[1].lower()
    
    if file_ext not in allowed_extensions:
        raise ValueError(f"ä¸å…è¨±çš„æª”æ¡ˆé¡å‹: {file_ext}")
    
    # ç”Ÿæˆå®‰å…¨çš„æª”æ¡ˆè·¯å¾‘
    safe_path = os.path.join(UPLOAD_FOLDER, filename)
    file.save(safe_path)
    return safe_path
```

---

## ğŸ“š é™„éŒ„

### A. å¸¸ç”¨æŒ‡ä»¤

```bash
# å‰ç«¯é–‹ç™¼
npm run dev          # å•Ÿå‹•é–‹ç™¼ä¼ºæœå™¨
npm run build        # å»ºç½®ç”Ÿç”¢ç‰ˆæœ¬
npm run preview      # é è¦½ç”Ÿç”¢ç‰ˆæœ¬
npm run type-check   # TypeScript é¡å‹æª¢æŸ¥

# å¾Œç«¯é–‹ç™¼
python app.py        # å•Ÿå‹• Flask é–‹ç™¼ä¼ºæœå™¨
python -m pytest    # åŸ·è¡Œæ¸¬è©¦
python health_check.py  # å¥åº·æª¢æŸ¥

# Docker éƒ¨ç½²
docker-compose up -d    # å•Ÿå‹•æœå‹™
docker-compose logs -f  # æŸ¥çœ‹æ—¥èªŒ
docker-compose down     # åœæ­¢æœå‹™
```

### B. ç›¸é—œè³‡æº

- [Vue 3 å®˜æ–¹æ–‡æª”](https://vuejs.org/)
- [PrimeVue çµ„ä»¶åº«](https://primevue.org/)
- [Flask å®˜æ–¹æ–‡æª”](https://flask.palletsprojects.com/)
- [OpenAI API æ–‡æª”](https://platform.openai.com/docs)
- [Claude API æ–‡æª”](https://docs.anthropic.com/)

---

**æœ¬æ–‡æª”æŒçºŒæ›´æ–°ä¸­ï¼Œå¦‚æœ‰å•é¡Œè«‹è¯ç¹«é–‹ç™¼åœ˜éšŠã€‚**